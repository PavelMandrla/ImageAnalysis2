## CNN
### Pooling
- vrstva ve které se snažíme redukovat dimenzi obrazu
  - má podobné parametry jako konvoluce
      - velikost třeba 2 = stride 2
          - bere maximální hodnoty z každého bloku a ty jdou dále
              - nebo suma, průměr...
- po konvoluci (můžu mít několik masek ve vrstvě) mám celou řadu obrazů, tím si mnohokrát zvýším dimenzi
  - chci to zmenšit => Pooling
v LeNet se za sebou konvoluce a poolingy vrství
- nakonec se dá fully connected layer
  - dá se to na vstupy neuronů, Ta CNN prakticky funguje jako feature extraction
    - dobré je, že je feature extraction spojena s klasifikátorem
      - masky se mění na základě chyby klasifikátoru
        - dostaneme lepší příznaky, síť se adaptuje na ten daný objekt
- to co má na slajdu k LeNet k Pytorchi můžeme použít na parkoviště tak, jak to je
  - bojový úkol - rozjet Pytorch

### AlexNET
  - za éry LeNet byly grafické karty příliš pomalé
  - s rychlejším hardwarem návrat ke konvolučním sítím
  - AlexNET - 2012
  - použito na soutěž imageNet - crushed it
  - relativně jednoduchá
  - rozděleno na vrchí a spodní část
    - každá část se trénovala na jiném gpu
    - liší se v počtu a velikosti masek
  - dropout
    - vyřazení některých neuronů
      - model je v některých situacích větší, než potřebujeme
      - fce dropout nám během tréninku sama některé neurony zruší
      - zjednodušuje se nám poslední fully connected vrstva
      - bez dropoutu docházelo k overfittingu
    - [dive into deep learning](https://d2l.ai/)
      - doporučený studijní materiál
    - p = 0.5
  - data augmentation
    - úprava vstupních obrázků
      - např u aut bychom přidali šum, aby to nějak simulovalo situaci v noci
  - přišlo se na to, že se ty sítě nedají vrstvit donekonečna
    - přestane se to zlepšovat, ale dokonce se to zhoršuje

### ZFNet
  - nepoužijeme na detekci/rozpoznávání
  - je na ní pěkné to, že představili síť, která obsahovala dekonvoluci
    - vizualizace toho, jak ty příznaky/obraz vypadají v různých těch vrstvách
    - přinesli představu, jak to v těch sítích funguje
      - v prvních vrstvách jsou příznaky velmi low level (rohy, hrany, ...)
      - později se objevují kontury objektů
        - dále se to zpřesnňuje a zpřesňuje
  - (transfer learning)
    - přišlo se na to, že hodně objektů má ty první vrstvy hodně podobné
      - rohy, hrany
    - další vrstvy jsou již class specific
    - když máme nějakou síť, tak můžeme vzít nějakou již předtrénovanou a dotrénujeme si poslední vrstvy, které se specializují na daný případ
      - zkrátí se trénovací doba

### VGGNet
  - na parkovišťích prý dosáhl úspěšnosti 99% bez úpravy datasetu
  - ten soubor, co to v Pytorchi natrénuje má prý půl giga
  - velmi hluboká "obluda"
  - použití VGG bloku
    - bloková reprezentace do konvolučních sítí
    - síť se dá skládat z bloků
  - navrhli jich několik - číslo za názvem sítě
    - počet vrstev - v nich jsou velké počty konvolučních masek
  - implementováno skoro všude
  - použít "_batch noramlization_" - další vrstva, kterou tam můžeme vložit
    - pomůže nám to rychleji konvergovat k nějakému výsledku

### GoogLeNet
  - je v ní Inception blok
    - "we have to go deeper"
      - hlubší než VGG
  - nešli pouze do hloubky
    - nevíme, jakou velikost kernelu použít? -> použijeme jich více
    - 3x3? 5x5? obě
      - udělají se dvě větve
        - ty se potom spojí a to jde na další vrstvu
      - tím jdeme i do šířky
        - šli více do šířky, než do hloubky
  - 1x1 konvoluce
    -  pro redukci dimenze prostoru
      - aby se vůbec dopočítali výsledku
    - vezmeme vstupní obraz a vynásobíme to skalárem
      - ve 2d prostoru to nemá smysl
    - je to 1x1 x počet kanálů
      - všechny ty kanály to smrskne do jednoho
        - 64x64x192 to zmenší do 64x64x1
    - může mi to výrazně zmenšit potřebný počet operací
    - rozšířit architekturu o noramlizaci dávky
      - pak by to trénování mohlo fungovat lépe
    - obhák pro lepší výsledky
      - použijeme models.googlenet(pretrained=True)

### ResNet
  - opět dopadla dobře v té soutěži
  - dnes jedna z nejpoužívanějších sítí, chceme-li něco rozpoznat
  - zkoumali, zda se dá donekonečna jít hlouběji
    - jestli čím více vrstev, tím lepší výsledek
    - udělali jednoduché sítě, na kterých to otestovali s datasetem CIFAR-10
    - přišli na to, že to nejde
      - 20ti vrstvá síť překonala 56ti vrstvou
    - čím to je?
      - ___Vanishing gradient issue___
        - problém mizejícího gradientu
        - čím hlouběji propagujeme informaci do sítě, tak následně musíme při backpropagation propagovat chybu stejně daleko
          - čím je síť hlubší, tím méně ovlivňuje první vrstvy
    - __shortcut connections__
      - obejdu některé konvoluční vrstvy
      - modifikuji ji, ale posílám ji i modifikovanou
      - na další vrstvě se sečtou modifikované hodnoty s těmi nemodifikovanými
      - díky tomuto se dají trénovat mnohem hlubší sítě s lepším výsledkem
        - informace nám nemizí
  - přemýšlelo se, jak to zrychlit
    - opět se použily 1x1 konvoluce na zmenšení dimenze
  - testy, zda používat Batch normalization před/za součtem
    - to samé s ReLU
  - varianty
    - dá se tím modifikovat řada již existujících architektur
    - _Inception ResNet_
    - _ResNeXt_ - jde více do šířky
    - v erroru už to ale jsou spíše otázky desetin
    - ___Dense Net___
      - na rozdíl od ResNetu jde informace za další blok, za další dva bloky, za další tři bloky, ...
      - informa se k tomu nepřičte, ale konkatanuje se na konec
- __transfer learning__ v pytorchi
  - aniž bychom museli síť implementovat
  - ty sítě se dají různě modifikovat i když použijeme variantu od nich
    - můžeme změnit parametry ve vrstvách
    - můžeme změnit vrstvu
    - optim.SGD(resnet18.fc.parameters(), ...) => změň parametry pouze v té poslední vrstvě

### použití sítí pro detekování
- chceme v obraze ty objekty najít ne je pouze klasifikovat
- nemáme geometrii parkoviště
  - mohli bychom natrénovat síť tak jak teď, pak se podívat na nějaké místo v obraze, vyříznout z něj obdélník a síť by nám řekla, zda je to prázdné místo, nebo plné
  - můžou v tom být problémy, protože v tom obraze jsou části, které v trénovacím datasetu vůbec nejsou
  - sliding window
  - pro různě velké objekty - musíme měnit velikost detekční okno, nebo měnit velikost obrazu
    - vede to k novému scanu
    - pomalé
- ___region based CNN___
  - _R-CNN_
  - vezmeme vstupní obraz
    - pomocí Selective search for object recognition algoritmu jsou v obrzaze nalezeny výřezy (ROI, proposals)
      - extrahují jich asi 2000
      - nasegmentuje mi to obraz
        - mnoho segmentů se společnými vlastnostmi, které můžeme dát do bounding boxů
  - bounding box se dá na vstup té sítě - ta nám to klasifikuje
  - problém
    - je nutné ten obrázek resiznout - musíme do sítě dostat fixní velikost
    - ty segmenty ale nemají takovou velikosti
      - dochází k deformaci toho obrazu, není to OK
  - Selective search for object recognition je i v opencv jako funkce
  - _Fast R-CNN_
    - ta původní metoda není zase tak rychlá
    - přidali ROI pooling layer a konvoluční feature mapu
      - předtím nebylo sdílení počítání příznaků mezi objekty
      - obraz proženeme sítí VGG - dostaneme menší obraz
        - v nějaké fázi VGG to usekli - dej mi obraz, co ti vyjde po páté vrstvě
          - vezme se feature mapa a na to se namapuje Selective search, který byl použit na původní obraz
      - abych ty příznaky nemuseli resizovat - ROI pooling
        - vezmou se hodnoty feature mapy, a oblast toho objektu
        - region se rozdělí do čtyř (n) částí, a z každé části se vezme maxpoolingem maximum
          - pokaždé získáme 4 hodnoty
            - 4 hodnoty * počet masek
        to se vezme a hodí se to do té fully connected vrstvy
  - _Faster R-CNN_
    - odstranění té segmentační metody
    - Region proposal network
      - z té páté vrstvy VGG hodíme feature mapy do té Region proposal network
        - ta hledá ROI v té feature mapě
    - pořád to ještě není ono
      - dva moduly, které spolu nějak kooperují
  - _Mask R-CNN_
    - extra síť, která dělá segmentaci
  - _YOLO_
    - you look only once
    - pouze jeden modul, snaží se ty objekty hledat najednou
